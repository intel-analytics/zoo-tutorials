{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding recurrent neural networks\n",
    "\n",
    "This notebook contains code migrated from samples found in Chapter 6, Section 2 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
    "\n",
    "\n",
    "## A first recurrent layer in PyTorch\n",
    "\n",
    "The process we just naively implemented in Numpy corresponds to an actual PyTorch layer: the `RNN` layer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is just one minor difference: `RNN` processes batches of sequences, not just a single sequence like in our Numpy example. This means that it takes inputs of shape `(seq_len, batch, input_size)`, rather than `(seq_len, input_size)`.\n",
    "\n",
    "Like all recurrent layers in PyTorh, `RNN` returns the full sequences of successive outputs for each time stamp (a 3D tensor of shape `(seq_len, batch, num_directions * hidden_size)`), and a tensor `h_n` of shape `(num_layers * num_directions, batch, hidden_size)`, which contains the hidden state for `t = seq_len`.  Let's take a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Network1(\n  (embedding): Embedding(10000, 32)\n  (rnn): RNN(32, 32)\n)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Network1(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim):\n",
    "        super(Network1, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "\n",
    "        return hidden   # return only the last output for each input sequence\n",
    "\n",
    "INPUT_DIM = 10000\n",
    "EMBEDDING_DIM = 32\n",
    "HIDDEN_DIM = 32\n",
    "\n",
    "model1 = Network1(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is sometimes useful to stack several recurrent layers one after the other in order to increase the representational power of a network. \n",
    "In such a setup, you have to get all intermediate layers to return full sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Network2(\n  (embedding): Embedding(10000, 32)\n  (rnn1): RNN(32, 32)\n  (rnn2): RNN(32, 32)\n  (rnn3): RNN(32, 32)\n  (rnn4): RNN(32, 32)\n)\n"
     ]
    }
   ],
   "source": [
    "class Network2(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim):\n",
    "        super(Network2, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn1 = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.rnn2 = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.rnn3 = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.rnn4 = nn.RNN(embedding_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.rnn1(embedded)\n",
    "        output, hidden = self.rnn2(output)\n",
    "        output, hidden = self.rnn3(output)\n",
    "        output, hidden = self.rnn4(output)\n",
    "\n",
    "        return hidden\n",
    "\n",
    "\n",
    "model2 = Network2(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to use such a model on the IMDB movie review classification problem. We will try to build a machine learning model to classify movie reviews into 2 categories: postive or negtive. The IMDB training set contains 25000 movie reviews labeled by sentiment (positive / negative). Since our model cannot process strings directly, we will use a preprocessed dataset `imdb.npz`, which has turned the words in the reviews into integers according to the frequency they appear in the dataset. For instance, the integer \"3\" encodes the 3rd most frequent word in the data. \n",
    "\n",
    "Before loading the dataset, let's first define some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_char = 1          # The start of a sequence will be marked with 1.\n",
    "num_words = 10000       # Number of words to consider as features. 10000 most frequent words are kept.\n",
    "maxlen = 500            # Maximum sequence length. Cut texts after this number of words.\n",
    "index_from=3            # Index actual words with this index and higher.\n",
    "oov_char=2              # Words that were cut out because of the num_words limit will be replaced with 2.\n",
    "pad_char = 0            # Padding value.\n",
    "batch_size = 128\n",
    "seed = 113"
   ]
  },
  {
   "source": [
    "Now we can begin our data processing. First let's load the dataset:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset loading finished.\nLength of training set:  25000\n"
     ]
    }
   ],
   "source": [
    "from bigdl.dataset import base\n",
    "import numpy as np\n",
    "\n",
    "def download_imdb(dest_dir):\n",
    "    \"\"\"Download pre-processed IMDB movie review data\n",
    "\n",
    "    :argument\n",
    "        dest_dir: destination directory to store the data\n",
    "    :return\n",
    "        The absolute path of the stored data\n",
    "    \"\"\"\n",
    "    file_name = \"imdb.npz\"\n",
    "    file_abs_path = base.maybe_download(file_name,\n",
    "                                        dest_dir,\n",
    "                                        'https://s3.amazonaws.com/text-datasets/imdb.npz')\n",
    "    return file_abs_path\n",
    "\n",
    "def load_imdb(dest_dir='/tmp/.bigdl/dataset'):\n",
    "    \"\"\"Load IMDB dataset.\n",
    "\n",
    "    :argument\n",
    "        dest_dir: where to cache the data (relative to `~/.bigdl/dataset`).\n",
    "    :return\n",
    "        the train, test separated IMDB dataset.\n",
    "    \"\"\"\n",
    "    path = download_imdb(dest_dir)\n",
    "    f = np.load(path, allow_pickle=True)\n",
    "    x_train = f['x_train']\n",
    "    y_train = f['y_train']\n",
    "    x_test = f['x_test']\n",
    "    y_test = f['y_test']\n",
    "    f.close()\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_imdb(dest_dir='.data/.bigdl/dataset')\n",
    "print(\"Dataset loading finished.\")\n",
    "print(\"Length of training set: \", len(x_train))"
   ]
  },
  {
   "source": [
    "Since only the training set of IMDB is used in this example, we will only preprocess the training set. Shuffle the data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed)\n",
    "indices = np.arange(len(x_train))\n",
    "rng.shuffle(indices)\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]"
   ]
  },
  {
   "source": [
    "Set the start character:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [[start_char] + [w + index_from for w in x] for x in x_train]"
   ]
  },
  {
   "source": [
    "Since we only consider `num_words` words (features) in this example, any word out of this range will be disgarded. The disgarded words are represented as `oov_char`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [[w if (w < num_words) else oov_char for w in x] for x in x_train]"
   ]
  },
  {
   "source": [
    "When we feed sequences into our model, all sequences in the batch need to be the same size: `maxlen`. Thus, to ensure each sentence in the batch is the same size, any shorter than `maxlen` needs to be padded, and any longer needs to be cut. `pad_char` is used to fill the blanks in the shorter sequences."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    l = len(x_train[i])\n",
    "    if l >= maxlen:\n",
    "        x_train[i] = x_train[i][(l - maxlen):]\n",
    "    else:\n",
    "        x_train[i] =[pad_char] * (maxlen - l) + x_train[i]"
   ]
  },
  {
   "source": [
    "To create a validation set, we can split the the training set with 25000 samples into two parts: 20000 samples for training and 5000 samples for validation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature, train_label = x_train[0:20000], y_train[0:20000]\n",
    "val_feature, val_label = x_train[20000:25000], y_train[20000:25000]"
   ]
  },
  {
   "source": [
    "Create data loaders for the training and validation datasets:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def create_data_loader(feature, label, batch_size, shuffle=True):\n",
    "    feature_tensor = torch.LongTensor(feature)\n",
    "    label_tensor = torch.FloatTensor(label).unsqueeze(1)\n",
    "    dataset = TensorDataset(feature_tensor, label_tensor)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "train_loader = create_data_loader(train_feature, train_label, batch_size)\n",
    "val_loader = create_data_loader(val_feature, val_label, batch_size, False)"
   ]
  },
  {
   "source": [
    "Now we are ready to create and train the model. First, initialize orca context:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initializing orca context\n",
      "Current pyspark location is : /intern/spark/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/__init__.py\n",
      "Start to getOrCreate SparkContext\n",
      "pyspark_submit_args is:  --driver-class-path /home/jinglei/analytics-zoo/zoo/target/analytics-zoo-bigdl_0.12.1-spark_2.4.3-0.10.0-SNAPSHOT-jar-with-dependencies.jar pyspark-shell \n",
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/jinglei/analytics-zoo/zoo/target/analytics-zoo-bigdl_0.12.1-spark_2.4.3-0.10.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/intern/spark/spark-2.4.3-bin-hadoop2.7/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2021-03-09 14:21:14 WARN  Utils:66 - Your hostname, intern01 resolves to a loopback address: 127.0.1.1; using 10.239.44.107 instead (on interface eno1)\n",
      "2021-03-09 14:21:14 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "2021-03-09 14:21:15 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2021-03-09 14:21:15 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "cls.getname: com.intel.analytics.bigdl.python.api.Sample\n",
      "BigDLBasePickler registering: bigdl.util.common  Sample\n",
      "cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult\n",
      "BigDLBasePickler registering: bigdl.util.common  EvaluatedResult\n",
      "cls.getname: com.intel.analytics.bigdl.python.api.JTensor\n",
      "BigDLBasePickler registering: bigdl.util.common  JTensor\n",
      "cls.getname: com.intel.analytics.bigdl.python.api.JActivity\n",
      "Successfully got a SparkContext\n",
      "BigDLBasePickler registering: bigdl.util.common  JActivity\n",
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=1\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_HAND_THREAD=false\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=false\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_FORKJOIN_FRAMES=true\n",
      "   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_INIT_WAIT=2048\n",
      "   KMP_ITT_PREPARE_DELAY=0\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NEXT_WAIT=1024\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=4M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=8\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USER_LEVEL_MWAIT=false\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED=false\n",
      "   OMP_NUM_THREADS='1'\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=4M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_TOOL=enabled\n",
      "   OMP_TOOL_LIBRARIES: value is not defined\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from zoo.orca import init_orca_context, stop_orca_context\n",
    "from zoo.orca import OrcaContext\n",
    "\n",
    "# recommended to set it to True when running Analytics Zoo in Jupyter notebook. \n",
    "OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n",
    "\n",
    "cluster_mode = \"local\"\n",
    "\n",
    "if cluster_mode == \"local\":\n",
    "    init_orca_context(cores=1, memory=\"2g\")   # run in local mode\n",
    "elif cluster_mode == \"k8s\":\n",
    "    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=4) # run on K8s cluster\n",
    "elif cluster_mode == \"yarn\":\n",
    "    init_orca_context(\n",
    "        cluster_mode=\"yarn-client\", cores=4, num_nodes=2, memory=\"2g\",\n",
    "        driver_memory=\"10g\", driver_cores=1,\n",
    "        conf={\"spark.rpc.message.maxSize\": \"1024\",\n",
    "              \"spark.task.maxFailures\": \"1\",\n",
    "              \"spark.driver.extraJavaOptions\": \"-Dbigdl.failure.retryTimes=1\"})   # run on Hadoop YARN cluster"
   ]
  },
  {
   "source": [
    "Create a simple recurrent network using an Embedding layer and an RNN layer:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SimpleRNN(\n  (embedding): Embedding(10000, 32)\n  (rnn): RNN(32, 32)\n  (fc): Linear(in_features=32, out_features=1, bias=True)\n  (out_act): Sigmoid()\n)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, 32)\n",
    "        for name, param in self.embedding.named_parameters(): \n",
    "            torch.nn.init.uniform_(param)\n",
    "        \n",
    "        self.rnn = nn.RNN(32, 32)\n",
    "        for name, param in self.rnn.named_parameters(): \n",
    "            if 'weight_ih' in name:\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                torch.nn.init.orthogonal_(param)\n",
    "            elif 'bias' in name:\n",
    "                torch.nn.init.zeros_(param)\n",
    "                \n",
    "        self.fc = nn.Linear(32, 1)\n",
    "        for name, param in self.rnn.named_parameters(): \n",
    "            if 'weight_ih' in name:\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                torch.nn.init.zeros_(param)\n",
    "                \n",
    "        self.out_act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text.transpose(0, 1))     # text: [128, 500] embedded: [500, 128, 32]\n",
    "        output, hidden = self.rnn(embedded)                 # hidden: [1, 128, 32]\n",
    "\n",
    "        es = \"output: \", output[-1,:,:].shape, \" hidden: \", hidden.shape\n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0)), es\n",
    "        \n",
    "        ret = self.fc(hidden.squeeze(0))                    # [128, 1]\n",
    "        #return ret.squeeze(1)\n",
    "        return self.out_act(ret)\n",
    "\n",
    "INPUT_DIM = 10000\n",
    "EMBEDDING_DIM = 32\n",
    "HIDDEN_DIM = 32\n",
    "\n",
    "model1 = SimpleRNN(INPUT_DIM)\n",
    "model1.train()\n",
    "print(model1)"
   ]
  },
  {
   "source": [
    "Specify loss function, optimizer and metrics:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zoo.orca.learn.metrics import Accuracy\n",
    "\n",
    "rmsprop = torch.optim.RMSprop(model1.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "metrics = [Accuracy()]"
   ]
  },
  {
   "source": [
    "Now we can start the training:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "er$:427 - [Epoch 3 9472/20096][Iteration 388][Wall Clock 144.384073535s] Trained 128.0 records in 0.34161007 seconds. Throughput is 374.6962 records/second. Loss is 0.53392375. \n",
      "2021-03-09 14:24:54 INFO  DistriOptimizer$:427 - [Epoch 3 9600/20096][Iteration 389][Wall Clock 144.777604127s] Trained 128.0 records in 0.393530592 seconds. Throughput is 325.26062 records/second. Loss is 0.6005465. \n",
      "2021-03-09 14:24:55 INFO  DistriOptimizer$:427 - [Epoch 3 9728/20096][Iteration 390][Wall Clock 145.11607802s] Trained 128.0 records in 0.338473893 seconds. Throughput is 378.16803 records/second. Loss is 0.5308614. \n",
      "2021-03-09 14:24:55 INFO  DistriOptimizer$:427 - [Epoch 3 9856/20096][Iteration 391][Wall Clock 145.45448695s] Trained 128.0 records in 0.33840893 seconds. Throughput is 378.24063 records/second. Loss is 0.4990787. \n",
      "2021-03-09 14:24:55 INFO  DistriOptimizer$:427 - [Epoch 3 9984/20096][Iteration 392][Wall Clock 145.795217412s] Trained 128.0 records in 0.340730462 seconds. Throughput is 375.6635 records/second. Loss is 0.49722847. \n",
      "2021-03-09 14:24:56 INFO  DistriOptimizer$:427 - [Epoch 3 10112/20096][Iteration 393][Wall Clock 146.150208604s] Trained 128.0 records in 0.354991192 seconds. Throughput is 360.57233 records/second. Loss is 0.46005136. \n",
      "2021-03-09 14:24:56 INFO  DistriOptimizer$:427 - [Epoch 3 10240/20096][Iteration 394][Wall Clock 146.494732861s] Trained 128.0 records in 0.344524257 seconds. Throughput is 371.5268 records/second. Loss is 0.5074373. \n",
      "2021-03-09 14:24:56 INFO  DistriOptimizer$:427 - [Epoch 3 10368/20096][Iteration 395][Wall Clock 146.834332447s] Trained 128.0 records in 0.339599586 seconds. Throughput is 376.9145 records/second. Loss is 0.54854214. \n",
      "2021-03-09 14:24:57 INFO  DistriOptimizer$:427 - [Epoch 3 10496/20096][Iteration 396][Wall Clock 147.182295663s] Trained 128.0 records in 0.347963216 seconds. Throughput is 367.85498 records/second. Loss is 0.46975607. \n",
      "2021-03-09 14:24:57 INFO  DistriOptimizer$:427 - [Epoch 3 10624/20096][Iteration 397][Wall Clock 147.519831696s] Trained 128.0 records in 0.337536033 seconds. Throughput is 379.21878 records/second. Loss is 0.5144757. \n",
      "2021-03-09 14:24:57 INFO  DistriOptimizer$:427 - [Epoch 3 10752/20096][Iteration 398][Wall Clock 147.867017722s] Trained 128.0 records in 0.347186026 seconds. Throughput is 368.67844 records/second. Loss is 0.50265014. \n",
      "2021-03-09 14:24:58 INFO  DistriOptimizer$:427 - [Epoch 3 10880/20096][Iteration 399][Wall Clock 148.192076325s] Trained 128.0 records in 0.325058603 seconds. Throughput is 393.77515 records/second. Loss is 0.5256943. \n",
      "2021-03-09 14:24:58 INFO  DistriOptimizer$:427 - [Epoch 3 11008/20096][Iteration 400][Wall Clock 148.528510413s] Trained 128.0 records in 0.336434088 seconds. Throughput is 380.46085 records/second. Loss is 0.50384575. \n",
      "2021-03-09 14:24:58 INFO  DistriOptimizer$:427 - [Epoch 3 11136/20096][Iteration 401][Wall Clock 148.836092917s] Trained 128.0 records in 0.307582504 seconds. Throughput is 416.14853 records/second. Loss is 0.5060095. \n",
      "2021-03-09 14:24:59 INFO  DistriOptimizer$:427 - [Epoch 3 11264/20096][Iteration 402][Wall Clock 149.219254382s] Trained 128.0 records in 0.383161465 seconds. Throughput is 334.06284 records/second. Loss is 0.7346313. \n",
      "2021-03-09 14:24:59 INFO  DistriOptimizer$:427 - [Epoch 3 11392/20096][Iteration 403][Wall Clock 149.582818667s] Trained 128.0 records in 0.363564285 seconds. Throughput is 352.0698 records/second. Loss is 0.5742318. \n",
      "2021-03-09 14:24:59 INFO  DistriOptimizer$:427 - [Epoch 3 11520/20096][Iteration 404][Wall Clock 149.957818692s] Trained 128.0 records in 0.375000025 seconds. Throughput is 341.3333 records/second. Loss is 0.4567106. \n",
      "2021-03-09 14:25:00 INFO  DistriOptimizer$:427 - [Epoch 3 11648/20096][Iteration 405][Wall Clock 150.277606315s] Trained 128.0 records in 0.319787623 seconds. Throughput is 400.26566 records/second. Loss is 0.53565925. \n",
      "2021-03-09 14:25:00 INFO  DistriOptimizer$:427 - [Epoch 3 11776/20096][Iteration 406][Wall Clock 150.603568865s] Trained 128.0 records in 0.32596255 seconds. Throughput is 392.68317 records/second. Loss is 0.537596. \n",
      "2021-03-09 14:25:00 INFO  DistriOptimizer$:427 - [Epoch 3 11904/20096][Iteration 407][Wall Clock 150.881993613s] Trained 128.0 records in 0.278424748 seconds. Throughput is 459.72925 records/second. Loss is 0.54682434. \n",
      "2021-03-09 14:25:01 INFO  DistriOptimizer$:427 - [Epoch 3 12032/20096][Iteration 408][Wall Clock 151.165195554s] Trained 128.0 records in 0.283201941 seconds. Throughput is 451.9743 records/second. Loss is 0.5242369. \n",
      "2021-03-09 14:25:01 INFO  DistriOptimizer$:427 - [Epoch 3 12160/20096][Iteration 409][Wall Clock 151.464226942s] Trained 128.0 records in 0.299031388 seconds. Throughput is 428.04874 records/second. Loss is 0.48843077. \n",
      "2021-03-09 14:25:01 INFO  DistriOptimizer$:427 - [Epoch 3 12288/20096][Iteration 410][Wall Clock 151.797519444s] Trained 128.0 records in 0.333292502 seconds. Throughput is 384.04703 records/second. Loss is 0.59184945. \n",
      "2021-03-09 14:25:02 INFO  DistriOptimizer$:427 - [Epoch 3 12416/20096][Iteration 411][Wall Clock 152.20628557s] Trained 128.0 records in 0.408766126 seconds. Throughput is 313.1375 records/second. Loss is 0.66751444. \n",
      "2021-03-09 14:25:02 INFO  DistriOptimizer$:427 - [Epoch 3 12544/20096][Iteration 412][Wall Clock 152.514509904s] Trained 128.0 records in 0.308224334 seconds. Throughput is 415.28195 records/second. Loss is 0.6283997. \n",
      "2021-03-09 14:25:02 INFO  DistriOptimizer$:427 - [Epoch 3 12672/20096][Iteration 413][Wall Clock 152.791400043s] Trained 128.0 records in 0.276890139 seconds. Throughput is 462.27722 records/second. Loss is 0.5449857. \n",
      "2021-03-09 14:25:03 INFO  DistriOptimizer$:427 - [Epoch 3 12800/20096][Iteration 414][Wall Clock 153.094293757s] Trained 128.0 records in 0.302893714 seconds. Throughput is 422.59045 records/second. Loss is 0.48835588. \n",
      "2021-03-09 14:25:03 INFO  DistriOptimizer$:427 - [Epoch 3 12928/20096][Iteration 415][Wall Clock 153.381444307s] Trained 128.0 records in 0.28715055 seconds. Throughput is 445.7592 records/second. Loss is 0.5527219. \n",
      "2021-03-09 14:25:03 INFO  DistriOptimizer$:427 - [Epoch 3 13056/20096][Iteration 416][Wall Clock 153.760783874s] Trained 128.0 records in 0.379339567 seconds. Throughput is 337.42853 records/second. Loss is 0.5239881. \n",
      "2021-03-09 14:25:04 INFO  DistriOptimizer$:427 - [Epoch 3 13184/20096][Iteration 417][Wall Clock 154.04895777s] Trained 128.0 records in 0.288173896 seconds. Throughput is 444.17627 records/second. Loss is 0.47853. \n",
      "2021-03-09 14:25:04 INFO  DistriOptimizer$:427 - [Epoch 3 13312/20096][Iteration 418][Wall Clock 154.340291696s] Trained 128.0 records in 0.291333926 seconds. Throughput is 439.3584 records/second. Loss is 0.49026048. \n",
      "2021-03-09 14:25:04 INFO  DistriOptimizer$:427 - [Epoch 3 13440/20096][Iteration 419][Wall Clock 154.591890213s] Trained 128.0 records in 0.251598517 seconds. Throughput is 508.74707 records/second. Loss is 0.516433. \n",
      "2021-03-09 14:25:04 INFO  DistriOptimizer$:427 - [Epoch 3 13568/20096][Iteration 420][Wall Clock 154.854281096s] Trained 128.0 records in 0.262390883 seconds. Throughput is 487.82184 records/second. Loss is 0.47868484. \n",
      "2021-03-09 14:25:05 INFO  DistriOptimizer$:427 - [Epoch 3 13696/20096][Iteration 421][Wall Clock 155.123017046s] Trained 128.0 records in 0.26873595 seconds. Throughput is 476.304 records/second. Loss is 0.529599. \n",
      "2021-03-09 14:25:05 INFO  DistriOptimizer$:427 - [Epoch 3 13824/20096][Iteration 422][Wall Clock 155.411881439s] Trained 128.0 records in 0.288864393 seconds. Throughput is 443.11447 records/second. Loss is 0.47863963. \n",
      "2021-03-09 14:25:05 INFO  DistriOptimizer$:427 - [Epoch 3 13952/20096][Iteration 423][Wall Clock 155.694537463s] Trained 128.0 records in 0.282656024 seconds. Throughput is 452.84726 records/second. Loss is 0.5365041. \n",
      "2021-03-09 14:25:06 INFO  DistriOptimizer$:427 - [Epoch 3 14080/20096][Iteration 424][Wall Clock 156.079162181s] Trained 128.0 records in 0.384624718 seconds. Throughput is 332.79193 records/second. Loss is 0.6743578. \n",
      "2021-03-09 14:25:06 INFO  DistriOptimizer$:427 - [Epoch 3 14208/20096][Iteration 425][Wall Clock 156.418108051s] Trained 128.0 records in 0.33894587 seconds. Throughput is 377.64142 records/second. Loss is 0.5567886. \n",
      "2021-03-09 14:25:06 INFO  DistriOptimizer$:427 - [Epoch 3 14336/20096][Iteration 426][Wall Clock 156.712384256s] Trained 128.0 records in 0.294276205 seconds. Throughput is 434.9655 records/second. Loss is 0.5213748. \n",
      "2021-03-09 14:25:07 INFO  DistriOptimizer$:427 - [Epoch 3 14464/20096][Iteration 427][Wall Clock 157.138569951s] Trained 128.0 records in 0.426185695 seconds. Throughput is 300.33856 records/second. Loss is 0.5755481. \n",
      "2021-03-09 14:25:07 INFO  DistriOptimizer$:427 - [Epoch 3 14592/20096][Iteration 428][Wall Clock 157.475587462s] Trained 128.0 records in 0.337017511 seconds. Throughput is 379.80222 records/second. Loss is 0.512699. \n",
      "2021-03-09 14:25:07 INFO  DistriOptimizer$:427 - [Epoch 3 14720/20096][Iteration 429][Wall Clock 157.840443705s] Trained 128.0 records in 0.364856243 seconds. Throughput is 350.8231 records/second. Loss is 0.51899266. \n",
      "2021-03-09 14:25:08 INFO  DistriOptimizer$:427 - [Epoch 3 14848/20096][Iteration 430][Wall Clock 158.160549284s] Trained 128.0 records in 0.320105579 seconds. Throughput is 399.86807 records/second. Loss is 0.50812644. \n",
      "2021-03-09 14:25:08 INFO  DistriOptimizer$:427 - [Epoch 3 14976/20096][Iteration 431][Wall Clock 158.53349064s] Trained 128.0 records in 0.372941356 seconds. Throughput is 343.2175 records/second. Loss is 0.5386834. \n",
      "2021-03-09 14:25:08 INFO  DistriOptimizer$:427 - [Epoch 3 15104/20096][Iteration 432][Wall Clock 158.828750416s] Trained 128.0 records in 0.295259776 seconds. Throughput is 433.51654 records/second. Loss is 0.45475125. \n",
      "2021-03-09 14:25:09 INFO  DistriOptimizer$:427 - [Epoch 3 15232/20096][Iteration 433][Wall Clock 159.12882751s] Trained 128.0 records in 0.300077094 seconds. Throughput is 426.55707 records/second. Loss is 0.5960759. \n",
      "2021-03-09 14:25:09 INFO  DistriOptimizer$:427 - [Epoch 3 15360/20096][Iteration 434][Wall Clock 159.502837369s] Trained 128.0 records in 0.374009859 seconds. Throughput is 342.23697 records/second. Loss is 0.60958683. \n",
      "2021-03-09 14:25:09 INFO  DistriOptimizer$:427 - [Epoch 3 15488/20096][Iteration 435][Wall Clock 159.829473098s] Trained 128.0 records in 0.326635729 seconds. Throughput is 391.87387 records/second. Loss is 0.5231476. \n",
      "2021-03-09 14:25:10 INFO  DistriOptimizer$:427 - [Epoch 3 15616/20096][Iteration 436][Wall Clock 160.165820876s] Trained 128.0 records in 0.336347778 seconds. Throughput is 380.55847 records/second. Loss is 0.51465327. \n",
      "2021-03-09 14:25:10 INFO  DistriOptimizer$:427 - [Epoch 3 15744/20096][Iteration 437][Wall Clock 160.504012162s] Trained 128.0 records in 0.338191286 seconds. Throughput is 378.484 records/second. Loss is 0.45357713. \n",
      "2021-03-09 14:25:10 INFO  DistriOptimizer$:427 - [Epoch 3 15872/20096][Iteration 438][Wall Clock 160.823210835s] Trained 128.0 records in 0.319198673 seconds. Throughput is 401.00418 records/second. Loss is 0.55840236. \n",
      "2021-03-09 14:25:11 INFO  DistriOptimizer$:427 - [Epoch 3 16000/20096][Iteration 439][Wall Clock 161.202501873s] Trained 128.0 records in 0.379291038 seconds. Throughput is 337.47174 records/second. Loss is 0.6980784. \n",
      "2021-03-09 14:25:11 INFO  DistriOptimizer$:427 - [Epoch 3 16128/20096][Iteration 440][Wall Clock 161.566590379s] Trained 128.0 records in 0.364088506 seconds. Throughput is 351.56287 records/second. Loss is 0.54950863. \n",
      "2021-03-09 14:25:11 INFO  DistriOptimizer$:427 - [Epoch 3 16256/20096][Iteration 441][Wall Clock 161.887411693s] Trained 128.0 records in 0.320821314 seconds. Throughput is 398.97598 records/second. Loss is 0.5047897. \n",
      "2021-03-09 14:25:12 INFO  DistriOptimizer$:427 - [Epoch 3 16384/20096][Iteration 442][Wall Clock 162.18858263s] Trained 128.0 records in 0.301170937 seconds. Throughput is 425.0078 records/second. Loss is 0.5028637. \n",
      "2021-03-09 14:25:12 INFO  DistriOptimizer$:427 - [Epoch 3 16512/20096][Iteration 443][Wall Clock 162.532304898s] Trained 128.0 records in 0.343722268 seconds. Throughput is 372.3937 records/second. Loss is 0.5531923. \n",
      "2021-03-09 14:25:12 INFO  DistriOptimizer$:427 - [Epoch 3 16640/20096][Iteration 444][Wall Clock 162.825800592s] Trained 128.0 records in 0.293495694 seconds. Throughput is 436.12225 records/second. Loss is 0.54808307. \n",
      "2021-03-09 14:25:13 INFO  DistriOptimizer$:427 - [Epoch 3 16768/20096][Iteration 445][Wall Clock 163.175158131s] Trained 128.0 records in 0.349357539 seconds. Throughput is 366.3868 records/second. Loss is 0.45294496. \n",
      "2021-03-09 14:25:13 INFO  DistriOptimizer$:427 - [Epoch 3 16896/20096][Iteration 446][Wall Clock 163.444428792s] Trained 128.0 records in 0.269270661 seconds. Throughput is 475.35815 records/second. Loss is 0.5225763. \n",
      "2021-03-09 14:25:13 INFO  DistriOptimizer$:427 - [Epoch 3 17024/20096][Iteration 447][Wall Clock 163.800703192s] Trained 128.0 records in 0.3562744 seconds. Throughput is 359.27365 records/second. Loss is 0.48612106. \n",
      "2021-03-09 14:25:14 INFO  DistriOptimizer$:427 - [Epoch 3 17152/20096][Iteration 448][Wall Clock 164.113170405s] Trained 128.0 records in 0.312467213 seconds. Throughput is 409.64297 records/second. Loss is 0.5892776. \n",
      "2021-03-09 14:25:14 INFO  DistriOptimizer$:427 - [Epoch 3 17280/20096][Iteration 449][Wall Clock 164.500207335s] Trained 128.0 records in 0.38703693 seconds. Throughput is 330.7178 records/second. Loss is 0.61978483. \n",
      "2021-03-09 14:25:14 INFO  DistriOptimizer$:427 - [Epoch 3 17408/20096][Iteration 450][Wall Clock 164.863731182s] Trained 128.0 records in 0.363523847 seconds. Throughput is 352.10895 records/second. Loss is 0.68293595. \n",
      "2021-03-09 14:25:15 INFO  DistriOptimizer$:427 - [Epoch 3 17536/20096][Iteration 451][Wall Clock 165.193657598s] Trained 128.0 records in 0.329926416 seconds. Throughput is 387.9653 records/second. Loss is 0.46479985. \n",
      "2021-03-09 14:25:15 INFO  DistriOptimizer$:427 - [Epoch 3 17664/20096][Iteration 452][Wall Clock 165.534276132s] Trained 128.0 records in 0.340618534 seconds. Throughput is 375.78696 records/second. Loss is 0.55409545. \n",
      "2021-03-09 14:25:15 INFO  DistriOptimizer$:427 - [Epoch 3 17792/20096][Iteration 453][Wall Clock 165.861225848s] Trained 128.0 records in 0.326949716 seconds. Throughput is 391.4975 records/second. Loss is 0.43253297. \n",
      "2021-03-09 14:25:16 INFO  DistriOptimizer$:427 - [Epoch 3 17920/20096][Iteration 454][Wall Clock 166.17901149s] Trained 128.0 records in 0.317785642 seconds. Throughput is 402.78723 records/second. Loss is 0.52163386. \n",
      "2021-03-09 14:25:16 INFO  DistriOptimizer$:427 - [Epoch 3 18048/20096][Iteration 455][Wall Clock 166.524206411s] Trained 128.0 records in 0.345194921 seconds. Throughput is 370.80496 records/second. Loss is 0.51878655. \n",
      "2021-03-09 14:25:16 INFO  DistriOptimizer$:427 - [Epoch 3 18176/20096][Iteration 456][Wall Clock 166.865483979s] Trained 128.0 records in 0.341277568 seconds. Throughput is 375.06128 records/second. Loss is 0.4924562. \n",
      "2021-03-09 14:25:17 INFO  DistriOptimizer$:427 - [Epoch 3 18304/20096][Iteration 457][Wall Clock 167.177547217s] Trained 128.0 records in 0.312063238 seconds. Throughput is 410.17325 records/second. Loss is 0.48212627. \n",
      "2021-03-09 14:25:17 INFO  DistriOptimizer$:427 - [Epoch 3 18432/20096][Iteration 458][Wall Clock 167.534891093s] Trained 128.0 records in 0.357343876 seconds. Throughput is 358.1984 records/second. Loss is 0.47737423. \n",
      "2021-03-09 14:25:17 INFO  DistriOptimizer$:427 - [Epoch 3 18560/20096][Iteration 459][Wall Clock 167.891685243s] Trained 128.0 records in 0.35679415 seconds. Throughput is 358.75027 records/second. Loss is 0.59057325. \n",
      "2021-03-09 14:25:18 INFO  DistriOptimizer$:427 - [Epoch 3 18688/20096][Iteration 460][Wall Clock 168.28278465s] Trained 128.0 records in 0.391099407 seconds. Throughput is 327.28253 records/second. Loss is 0.60833246. \n",
      "2021-03-09 14:25:18 INFO  DistriOptimizer$:427 - [Epoch 3 18816/20096][Iteration 461][Wall Clock 168.647593055s] Trained 128.0 records in 0.364808405 seconds. Throughput is 350.8691 records/second. Loss is 0.5557896. \n",
      "2021-03-09 14:25:19 INFO  DistriOptimizer$:427 - [Epoch 3 18944/20096][Iteration 462][Wall Clock 169.00614428s] Trained 128.0 records in 0.358551225 seconds. Throughput is 356.99222 records/second. Loss is 0.5305166. \n",
      "2021-03-09 14:25:19 INFO  DistriOptimizer$:427 - [Epoch 3 19072/20096][Iteration 463][Wall Clock 169.366825627s] Trained 128.0 records in 0.360681347 seconds. Throughput is 354.88388 records/second. Loss is 0.5128447. \n",
      "2021-03-09 14:25:19 INFO  DistriOptimizer$:427 - [Epoch 3 19200/20096][Iteration 464][Wall Clock 169.693683747s] Trained 128.0 records in 0.32685812 seconds. Throughput is 391.6072 records/second. Loss is 0.5183657. \n",
      "2021-03-09 14:25:20 INFO  DistriOptimizer$:427 - [Epoch 3 19328/20096][Iteration 465][Wall Clock 170.028594795s] Trained 128.0 records in 0.334911048 seconds. Throughput is 382.19104 records/second. Loss is 0.5075489. \n",
      "2021-03-09 14:25:20 INFO  DistriOptimizer$:427 - [Epoch 3 19456/20096][Iteration 466][Wall Clock 170.362701224s] Trained 128.0 records in 0.334106429 seconds. Throughput is 383.11148 records/second. Loss is 0.48736176. \n",
      "2021-03-09 14:25:20 INFO  DistriOptimizer$:427 - [Epoch 3 19584/20096][Iteration 467][Wall Clock 170.699216163s] Trained 128.0 records in 0.336514939 seconds. Throughput is 380.36945 records/second. Loss is 0.48175415. \n",
      "2021-03-09 14:25:21 INFO  DistriOptimizer$:427 - [Epoch 3 19712/20096][Iteration 468][Wall Clock 171.043312789s] Trained 128.0 records in 0.344096626 seconds. Throughput is 371.98853 records/second. Loss is 0.48952463. \n",
      "2021-03-09 14:25:21 INFO  DistriOptimizer$:427 - [Epoch 3 19840/20096][Iteration 469][Wall Clock 171.392065892s] Trained 128.0 records in 0.348753103 seconds. Throughput is 367.02182 records/second. Loss is 0.41172302. \n",
      "2021-03-09 14:25:21 INFO  DistriOptimizer$:427 - [Epoch 3 19968/20096][Iteration 470][Wall Clock 171.720164973s] Trained 128.0 records in 0.328099081 seconds. Throughput is 390.12607 records/second. Loss is 0.4671561. \n",
      "2021-03-09 14:25:21 INFO  DistriOptimizer$:427 - [Epoch 3 20096/20096][Iteration 471][Wall Clock 171.885972883s] Trained 128.0 records in 0.16580791 seconds. Throughput is 771.97766 records/second. Loss is 0.5356699. \n",
      "2021-03-09 14:25:21 INFO  DistriOptimizer$:472 - [Epoch 3 20096/20096][Iteration 471][Wall Clock 171.885972883s] Epoch finished. Wall clock time is 173567.037292 ms\n",
      "2021-03-09 14:25:21 INFO  DistriOptimizer$:111 - [Epoch 3 20096/20096][Iteration 471][Wall Clock 171.885972883s] Validate model...\n",
      "[Stage 953:>                                                        (0 + 1) / 1]Warn: jep.JepException: <class 'StopIteration'>\n",
      "\tat jep.Jep.exec(Native Method)\n",
      "\tat jep.Jep.exec(Jep.java:478)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "2021-03-09 14:25:23 INFO  DistriOptimizer$:177 - [Epoch 3 20096/20096][Iteration 471][Wall Clock 171.885972883s] validate model throughput is 3360.7014 records/second\n",
      "2021-03-09 14:25:23 INFO  DistriOptimizer$:180 - [Epoch 3 20096/20096][Iteration 471][Wall Clock 171.885972883s] Top1Accuracy is Accuracy(correct: 3462, count: 5000, accuracy: 0.6924)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<zoo.orca.learn.pytorch.estimator.PyTorchSparkEstimator at 0x7f6fd8711950>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from zoo.orca.learn.pytorch import Estimator\n",
    "from zoo.orca.learn.trigger import EveryEpoch\n",
    "\n",
    "est = Estimator.from_torch(model=model1, optimizer=rmsprop, loss=criterion, metrics=metrics)\n",
    "est.fit(data=train_loader, epochs=3, validation_data=val_loader, batch_size=batch_size, checkpoint_trigger=EveryEpoch())"
   ]
  },
  {
   "source": [
    "## A concrete LSTM example in Pytorch\n",
    "\n",
    "Now let's switch to more practical concerns: we will set up a model using a LSTM layer and train it on the IMDB data. Here's the network, similar to the one with `RNN` that we just presented. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SimpleLSTM(\n  (embedding): Embedding(10000, 32)\n  (lstm): LSTM(32, 32)\n  (fc): Linear(in_features=32, out_features=1, bias=True)\n  (out_act): Sigmoid()\n)\n"
     ]
    }
   ],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, 32) \n",
    "        self.lstm = nn.LSTM(32, 32)            \n",
    "        self.fc = nn.Linear(32, 1)               \n",
    "        self.out_act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text.transpose(0, 1))     \n",
    "        output, hidden = self.lstm(embedded)                \n",
    "        ret = self.fc(hidden[0].squeeze(0))                    \n",
    "        return self.out_act(ret)\n",
    "\n",
    "model2 = SimpleLSTM(INPUT_DIM)\n",
    "model2.train()\n",
    "print(model2)"
   ]
  },
  {
   "source": [
    "Now we can start the training:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "$:427 - [Epoch 3 9472/20096][Iteration 388][Wall Clock 224.059530478s] Trained 128.0 records in 0.345117653 seconds. Throughput is 370.888 records/second. Loss is 0.37704766. \n",
      "2021-03-09 14:31:26 INFO  DistriOptimizer$:427 - [Epoch 3 9600/20096][Iteration 389][Wall Clock 224.403340154s] Trained 128.0 records in 0.343809676 seconds. Throughput is 372.299 records/second. Loss is 0.43701047. \n",
      "2021-03-09 14:31:26 INFO  DistriOptimizer$:427 - [Epoch 3 9728/20096][Iteration 390][Wall Clock 224.751794924s] Trained 128.0 records in 0.34845477 seconds. Throughput is 367.33606 records/second. Loss is 0.50943863. \n",
      "2021-03-09 14:31:27 INFO  DistriOptimizer$:427 - [Epoch 3 9856/20096][Iteration 391][Wall Clock 225.106102978s] Trained 128.0 records in 0.354308054 seconds. Throughput is 361.26752 records/second. Loss is 0.47629723. \n",
      "2021-03-09 14:31:27 INFO  DistriOptimizer$:427 - [Epoch 3 9984/20096][Iteration 392][Wall Clock 225.469874998s] Trained 128.0 records in 0.36377202 seconds. Throughput is 351.8687 records/second. Loss is 0.44909197. \n",
      "2021-03-09 14:31:28 INFO  DistriOptimizer$:427 - [Epoch 3 10112/20096][Iteration 393][Wall Clock 225.814494898s] Trained 128.0 records in 0.3446199 seconds. Throughput is 371.4237 records/second. Loss is 0.3968174. \n",
      "2021-03-09 14:31:28 INFO  DistriOptimizer$:427 - [Epoch 3 10240/20096][Iteration 394][Wall Clock 226.153504633s] Trained 128.0 records in 0.339009735 seconds. Throughput is 377.57028 records/second. Loss is 0.44016066. \n",
      "2021-03-09 14:31:28 INFO  DistriOptimizer$:427 - [Epoch 3 10368/20096][Iteration 395][Wall Clock 226.496513742s] Trained 128.0 records in 0.343009109 seconds. Throughput is 373.16794 records/second. Loss is 0.412202. \n",
      "2021-03-09 14:31:29 INFO  DistriOptimizer$:427 - [Epoch 3 10496/20096][Iteration 396][Wall Clock 226.838824672s] Trained 128.0 records in 0.34231093 seconds. Throughput is 373.92905 records/second. Loss is 0.47894552. \n",
      "2021-03-09 14:31:29 INFO  DistriOptimizer$:427 - [Epoch 3 10624/20096][Iteration 397][Wall Clock 227.188386654s] Trained 128.0 records in 0.349561982 seconds. Throughput is 366.17255 records/second. Loss is 0.4201678. \n",
      "2021-03-09 14:31:29 INFO  DistriOptimizer$:427 - [Epoch 3 10752/20096][Iteration 398][Wall Clock 227.526893504s] Trained 128.0 records in 0.33850685 seconds. Throughput is 378.1312 records/second. Loss is 0.49432155. \n",
      "2021-03-09 14:31:30 INFO  DistriOptimizer$:427 - [Epoch 3 10880/20096][Iteration 399][Wall Clock 227.878789969s] Trained 128.0 records in 0.351896465 seconds. Throughput is 363.74335 records/second. Loss is 0.431669. \n",
      "2021-03-09 14:31:30 INFO  DistriOptimizer$:427 - [Epoch 3 11008/20096][Iteration 400][Wall Clock 228.221874284s] Trained 128.0 records in 0.343084315 seconds. Throughput is 373.08615 records/second. Loss is 0.38764825. \n",
      "2021-03-09 14:31:30 INFO  DistriOptimizer$:427 - [Epoch 3 11136/20096][Iteration 401][Wall Clock 228.560275428s] Trained 128.0 records in 0.338401144 seconds. Throughput is 378.24933 records/second. Loss is 0.43516392. \n",
      "2021-03-09 14:31:31 INFO  DistriOptimizer$:427 - [Epoch 3 11264/20096][Iteration 402][Wall Clock 228.909665143s] Trained 128.0 records in 0.349389715 seconds. Throughput is 366.3531 records/second. Loss is 0.5490807. \n",
      "2021-03-09 14:31:31 INFO  DistriOptimizer$:427 - [Epoch 3 11392/20096][Iteration 403][Wall Clock 229.258410878s] Trained 128.0 records in 0.348745735 seconds. Throughput is 367.02957 records/second. Loss is 0.53218096. \n",
      "2021-03-09 14:31:31 INFO  DistriOptimizer$:427 - [Epoch 3 11520/20096][Iteration 404][Wall Clock 229.608543198s] Trained 128.0 records in 0.35013232 seconds. Throughput is 365.57608 records/second. Loss is 0.45542622. \n",
      "2021-03-09 14:31:32 INFO  DistriOptimizer$:427 - [Epoch 3 11648/20096][Iteration 405][Wall Clock 229.958436635s] Trained 128.0 records in 0.349893437 seconds. Throughput is 365.82565 records/second. Loss is 0.5250648. \n",
      "2021-03-09 14:31:32 INFO  DistriOptimizer$:427 - [Epoch 3 11776/20096][Iteration 406][Wall Clock 230.303514426s] Trained 128.0 records in 0.345077791 seconds. Throughput is 370.93088 records/second. Loss is 0.37340233. \n",
      "2021-03-09 14:31:32 INFO  DistriOptimizer$:427 - [Epoch 3 11904/20096][Iteration 407][Wall Clock 230.644476176s] Trained 128.0 records in 0.34096175 seconds. Throughput is 375.40866 records/second. Loss is 0.5091631. \n",
      "2021-03-09 14:31:33 INFO  DistriOptimizer$:427 - [Epoch 3 12032/20096][Iteration 408][Wall Clock 231.020673089s] Trained 128.0 records in 0.376196913 seconds. Throughput is 340.24734 records/second. Loss is 0.46347237. \n",
      "2021-03-09 14:31:33 INFO  DistriOptimizer$:427 - [Epoch 3 12160/20096][Iteration 409][Wall Clock 231.363467563s] Trained 128.0 records in 0.342794474 seconds. Throughput is 373.40158 records/second. Loss is 0.39728817. \n",
      "2021-03-09 14:31:33 INFO  DistriOptimizer$:427 - [Epoch 3 12288/20096][Iteration 410][Wall Clock 231.71110949s] Trained 128.0 records in 0.347641927 seconds. Throughput is 368.19495 records/second. Loss is 0.4055972. \n",
      "2021-03-09 14:31:34 INFO  DistriOptimizer$:427 - [Epoch 3 12416/20096][Iteration 411][Wall Clock 232.054633306s] Trained 128.0 records in 0.343523816 seconds. Throughput is 372.6088 records/second. Loss is 0.40450135. \n",
      "2021-03-09 14:31:34 INFO  DistriOptimizer$:427 - [Epoch 3 12544/20096][Iteration 412][Wall Clock 232.441372625s] Trained 128.0 records in 0.386739319 seconds. Throughput is 330.9723 records/second. Loss is 0.5257724. \n",
      "2021-03-09 14:31:34 INFO  DistriOptimizer$:427 - [Epoch 3 12672/20096][Iteration 413][Wall Clock 232.801829964s] Trained 128.0 records in 0.360457339 seconds. Throughput is 355.10443 records/second. Loss is 0.46192285. \n",
      "2021-03-09 14:31:35 INFO  DistriOptimizer$:427 - [Epoch 3 12800/20096][Iteration 414][Wall Clock 233.146041291s] Trained 128.0 records in 0.344211327 seconds. Throughput is 371.86456 records/second. Loss is 0.47352213. \n",
      "2021-03-09 14:31:35 INFO  DistriOptimizer$:427 - [Epoch 3 12928/20096][Iteration 415][Wall Clock 233.489278889s] Trained 128.0 records in 0.343237598 seconds. Throughput is 372.9195 records/second. Loss is 0.4714356. \n",
      "2021-03-09 14:31:36 INFO  DistriOptimizer$:427 - [Epoch 3 13056/20096][Iteration 416][Wall Clock 233.843811319s] Trained 128.0 records in 0.35453243 seconds. Throughput is 361.0389 records/second. Loss is 0.4878004. \n",
      "2021-03-09 14:31:36 INFO  DistriOptimizer$:427 - [Epoch 3 13184/20096][Iteration 417][Wall Clock 234.184508711s] Trained 128.0 records in 0.340697392 seconds. Throughput is 375.69998 records/second. Loss is 0.44812945. \n",
      "2021-03-09 14:31:36 INFO  DistriOptimizer$:427 - [Epoch 3 13312/20096][Iteration 418][Wall Clock 234.539882467s] Trained 128.0 records in 0.355373756 seconds. Throughput is 360.18414 records/second. Loss is 0.45976448. \n",
      "2021-03-09 14:31:37 INFO  DistriOptimizer$:427 - [Epoch 3 13440/20096][Iteration 419][Wall Clock 234.882373326s] Trained 128.0 records in 0.342490859 seconds. Throughput is 373.7326 records/second. Loss is 0.4711768. \n",
      "2021-03-09 14:31:37 INFO  DistriOptimizer$:427 - [Epoch 3 13568/20096][Iteration 420][Wall Clock 235.239971355s] Trained 128.0 records in 0.357598029 seconds. Throughput is 357.9438 records/second. Loss is 0.37301058. \n",
      "2021-03-09 14:31:37 INFO  DistriOptimizer$:427 - [Epoch 3 13696/20096][Iteration 421][Wall Clock 235.583119874s] Trained 128.0 records in 0.343148519 seconds. Throughput is 373.01633 records/second. Loss is 0.46399045. \n",
      "2021-03-09 14:31:38 INFO  DistriOptimizer$:427 - [Epoch 3 13824/20096][Iteration 422][Wall Clock 235.922191574s] Trained 128.0 records in 0.3390717 seconds. Throughput is 377.50128 records/second. Loss is 0.5141651. \n",
      "2021-03-09 14:31:38 INFO  DistriOptimizer$:427 - [Epoch 3 13952/20096][Iteration 423][Wall Clock 236.271948895s] Trained 128.0 records in 0.349757321 seconds. Throughput is 365.96805 records/second. Loss is 0.45038164. \n",
      "2021-03-09 14:31:38 INFO  DistriOptimizer$:427 - [Epoch 3 14080/20096][Iteration 424][Wall Clock 236.624738837s] Trained 128.0 records in 0.352789942 seconds. Throughput is 362.82214 records/second. Loss is 0.44382453. \n",
      "2021-03-09 14:31:39 INFO  DistriOptimizer$:427 - [Epoch 3 14208/20096][Iteration 425][Wall Clock 236.962491274s] Trained 128.0 records in 0.337752437 seconds. Throughput is 378.9758 records/second. Loss is 0.41168958. \n",
      "2021-03-09 14:31:39 INFO  DistriOptimizer$:427 - [Epoch 3 14336/20096][Iteration 426][Wall Clock 237.308498657s] Trained 128.0 records in 0.346007383 seconds. Throughput is 369.9343 records/second. Loss is 0.48256826. \n",
      "2021-03-09 14:31:39 INFO  DistriOptimizer$:427 - [Epoch 3 14464/20096][Iteration 427][Wall Clock 237.670269002s] Trained 128.0 records in 0.361770345 seconds. Throughput is 353.81564 records/second. Loss is 0.44298336. \n",
      "2021-03-09 14:31:40 INFO  DistriOptimizer$:427 - [Epoch 3 14592/20096][Iteration 428][Wall Clock 238.012861609s] Trained 128.0 records in 0.342592607 seconds. Throughput is 373.6216 records/second. Loss is 0.46284. \n",
      "2021-03-09 14:31:40 INFO  DistriOptimizer$:427 - [Epoch 3 14720/20096][Iteration 429][Wall Clock 238.373663871s] Trained 128.0 records in 0.360802262 seconds. Throughput is 354.76495 records/second. Loss is 0.40597376. \n",
      "2021-03-09 14:31:40 INFO  DistriOptimizer$:427 - [Epoch 3 14848/20096][Iteration 430][Wall Clock 238.73103791s] Trained 128.0 records in 0.357374039 seconds. Throughput is 358.16815 records/second. Loss is 0.38650563. \n",
      "2021-03-09 14:31:41 INFO  DistriOptimizer$:427 - [Epoch 3 14976/20096][Iteration 431][Wall Clock 239.072687844s] Trained 128.0 records in 0.341649934 seconds. Throughput is 374.6525 records/second. Loss is 0.50882024. \n",
      "2021-03-09 14:31:41 INFO  DistriOptimizer$:427 - [Epoch 3 15104/20096][Iteration 432][Wall Clock 239.42009989s] Trained 128.0 records in 0.347412046 seconds. Throughput is 368.43857 records/second. Loss is 0.4970504. \n",
      "2021-03-09 14:31:41 INFO  DistriOptimizer$:427 - [Epoch 3 15232/20096][Iteration 433][Wall Clock 239.777804845s] Trained 128.0 records in 0.357704955 seconds. Throughput is 357.8368 records/second. Loss is 0.5512859. \n",
      "2021-03-09 14:31:42 INFO  DistriOptimizer$:427 - [Epoch 3 15360/20096][Iteration 434][Wall Clock 240.124185297s] Trained 128.0 records in 0.346380452 seconds. Throughput is 369.5359 records/second. Loss is 0.514024. \n",
      "2021-03-09 14:31:42 INFO  DistriOptimizer$:427 - [Epoch 3 15488/20096][Iteration 435][Wall Clock 240.469010527s] Trained 128.0 records in 0.34482523 seconds. Throughput is 371.2025 records/second. Loss is 0.4601653. \n",
      "2021-03-09 14:31:43 INFO  DistriOptimizer$:427 - [Epoch 3 15616/20096][Iteration 436][Wall Clock 240.824570348s] Trained 128.0 records in 0.355559821 seconds. Throughput is 359.99567 records/second. Loss is 0.43552414. \n",
      "2021-03-09 14:31:43 INFO  DistriOptimizer$:427 - [Epoch 3 15744/20096][Iteration 437][Wall Clock 241.165963935s] Trained 128.0 records in 0.341393587 seconds. Throughput is 374.9338 records/second. Loss is 0.3927957. \n",
      "2021-03-09 14:31:43 INFO  DistriOptimizer$:427 - [Epoch 3 15872/20096][Iteration 438][Wall Clock 241.502358559s] Trained 128.0 records in 0.336394624 seconds. Throughput is 380.50546 records/second. Loss is 0.4315799. \n",
      "2021-03-09 14:31:44 INFO  DistriOptimizer$:427 - [Epoch 3 16000/20096][Iteration 439][Wall Clock 241.868267864s] Trained 128.0 records in 0.365909305 seconds. Throughput is 349.81345 records/second. Loss is 0.47759756. \n",
      "2021-03-09 14:31:44 INFO  DistriOptimizer$:427 - [Epoch 3 16128/20096][Iteration 440][Wall Clock 242.205038565s] Trained 128.0 records in 0.336770701 seconds. Throughput is 380.08057 records/second. Loss is 0.43659922. \n",
      "2021-03-09 14:31:44 INFO  DistriOptimizer$:427 - [Epoch 3 16256/20096][Iteration 441][Wall Clock 242.667186473s] Trained 128.0 records in 0.462147908 seconds. Throughput is 276.9676 records/second. Loss is 0.39942834. \n",
      "2021-03-09 14:31:45 INFO  DistriOptimizer$:427 - [Epoch 3 16384/20096][Iteration 442][Wall Clock 243.023468253s] Trained 128.0 records in 0.35628178 seconds. Throughput is 359.26617 records/second. Loss is 0.48509526. \n",
      "2021-03-09 14:31:45 INFO  DistriOptimizer$:427 - [Epoch 3 16512/20096][Iteration 443][Wall Clock 243.37141595s] Trained 128.0 records in 0.347947697 seconds. Throughput is 367.8714 records/second. Loss is 0.41894084. \n",
      "2021-03-09 14:31:45 INFO  DistriOptimizer$:427 - [Epoch 3 16640/20096][Iteration 444][Wall Clock 243.703880842s] Trained 128.0 records in 0.332464892 seconds. Throughput is 385.00305 records/second. Loss is 0.4405924. \n",
      "2021-03-09 14:31:46 INFO  DistriOptimizer$:427 - [Epoch 3 16768/20096][Iteration 445][Wall Clock 244.04539965s] Trained 128.0 records in 0.341518808 seconds. Throughput is 374.79633 records/second. Loss is 0.4244772. \n",
      "2021-03-09 14:31:46 INFO  DistriOptimizer$:427 - [Epoch 3 16896/20096][Iteration 446][Wall Clock 244.413499977s] Trained 128.0 records in 0.368100327 seconds. Throughput is 347.7313 records/second. Loss is 0.4846069. \n",
      "2021-03-09 14:31:46 INFO  DistriOptimizer$:427 - [Epoch 3 17024/20096][Iteration 447][Wall Clock 244.761447588s] Trained 128.0 records in 0.347947611 seconds. Throughput is 367.8715 records/second. Loss is 0.45305797. \n",
      "2021-03-09 14:31:47 INFO  DistriOptimizer$:427 - [Epoch 3 17152/20096][Iteration 448][Wall Clock 245.131247602s] Trained 128.0 records in 0.369800014 seconds. Throughput is 346.13306 records/second. Loss is 0.41449282. \n",
      "2021-03-09 14:31:47 INFO  DistriOptimizer$:427 - [Epoch 3 17280/20096][Iteration 449][Wall Clock 245.479705596s] Trained 128.0 records in 0.348457994 seconds. Throughput is 367.33264 records/second. Loss is 0.3860903. \n",
      "2021-03-09 14:31:48 INFO  DistriOptimizer$:427 - [Epoch 3 17408/20096][Iteration 450][Wall Clock 245.835387114s] Trained 128.0 records in 0.355681518 seconds. Throughput is 359.87253 records/second. Loss is 0.52486473. \n",
      "2021-03-09 14:31:48 INFO  DistriOptimizer$:427 - [Epoch 3 17536/20096][Iteration 451][Wall Clock 246.184676997s] Trained 128.0 records in 0.349289883 seconds. Throughput is 366.4578 records/second. Loss is 0.50560784. \n",
      "2021-03-09 14:31:48 INFO  DistriOptimizer$:427 - [Epoch 3 17664/20096][Iteration 452][Wall Clock 246.540050784s] Trained 128.0 records in 0.355373787 seconds. Throughput is 360.1841 records/second. Loss is 0.43685955. \n",
      "2021-03-09 14:31:49 INFO  DistriOptimizer$:427 - [Epoch 3 17792/20096][Iteration 453][Wall Clock 246.895538529s] Trained 128.0 records in 0.355487745 seconds. Throughput is 360.0687 records/second. Loss is 0.38132954. \n",
      "2021-03-09 14:31:49 INFO  DistriOptimizer$:427 - [Epoch 3 17920/20096][Iteration 454][Wall Clock 247.247203954s] Trained 128.0 records in 0.351665425 seconds. Throughput is 363.98233 records/second. Loss is 0.35432625. \n",
      "2021-03-09 14:31:49 INFO  DistriOptimizer$:427 - [Epoch 3 18048/20096][Iteration 455][Wall Clock 247.604347791s] Trained 128.0 records in 0.357143837 seconds. Throughput is 358.39902 records/second. Loss is 0.44869417. \n",
      "2021-03-09 14:31:50 INFO  DistriOptimizer$:427 - [Epoch 3 18176/20096][Iteration 456][Wall Clock 247.966269526s] Trained 128.0 records in 0.361921735 seconds. Throughput is 353.66763 records/second. Loss is 0.4312682. \n",
      "2021-03-09 14:31:50 INFO  DistriOptimizer$:427 - [Epoch 3 18304/20096][Iteration 457][Wall Clock 248.327094992s] Trained 128.0 records in 0.360825466 seconds. Throughput is 354.74213 records/second. Loss is 0.405349. \n",
      "2021-03-09 14:31:50 INFO  DistriOptimizer$:427 - [Epoch 3 18432/20096][Iteration 458][Wall Clock 248.683233703s] Trained 128.0 records in 0.356138711 seconds. Throughput is 359.41052 records/second. Loss is 0.35203177. \n",
      "2021-03-09 14:31:51 INFO  DistriOptimizer$:427 - [Epoch 3 18560/20096][Iteration 459][Wall Clock 249.028811258s] Trained 128.0 records in 0.345577555 seconds. Throughput is 370.3944 records/second. Loss is 0.34974542. \n",
      "2021-03-09 14:31:51 INFO  DistriOptimizer$:427 - [Epoch 3 18688/20096][Iteration 460][Wall Clock 249.378152944s] Trained 128.0 records in 0.349341686 seconds. Throughput is 366.40344 records/second. Loss is 0.44992328. \n",
      "2021-03-09 14:31:51 INFO  DistriOptimizer$:427 - [Epoch 3 18816/20096][Iteration 461][Wall Clock 249.717852576s] Trained 128.0 records in 0.339699632 seconds. Throughput is 376.80347 records/second. Loss is 0.483032. \n",
      "2021-03-09 14:31:52 INFO  DistriOptimizer$:427 - [Epoch 3 18944/20096][Iteration 462][Wall Clock 250.065201793s] Trained 128.0 records in 0.347349217 seconds. Throughput is 368.50522 records/second. Loss is 0.359943. \n",
      "2021-03-09 14:31:52 INFO  DistriOptimizer$:427 - [Epoch 3 19072/20096][Iteration 463][Wall Clock 250.415324761s] Trained 128.0 records in 0.350122968 seconds. Throughput is 365.58585 records/second. Loss is 0.43957305. \n",
      "2021-03-09 14:31:52 INFO  DistriOptimizer$:427 - [Epoch 3 19200/20096][Iteration 464][Wall Clock 250.771572048s] Trained 128.0 records in 0.356247287 seconds. Throughput is 359.301 records/second. Loss is 0.41986084. \n",
      "2021-03-09 14:31:53 INFO  DistriOptimizer$:427 - [Epoch 3 19328/20096][Iteration 465][Wall Clock 251.129238626s] Trained 128.0 records in 0.357666578 seconds. Throughput is 357.8752 records/second. Loss is 0.4930416. \n",
      "2021-03-09 14:31:53 INFO  DistriOptimizer$:427 - [Epoch 3 19456/20096][Iteration 466][Wall Clock 251.482722012s] Trained 128.0 records in 0.353483386 seconds. Throughput is 362.11038 records/second. Loss is 0.33176535. \n",
      "2021-03-09 14:31:54 INFO  DistriOptimizer$:427 - [Epoch 3 19584/20096][Iteration 467][Wall Clock 251.831827784s] Trained 128.0 records in 0.349105772 seconds. Throughput is 366.65106 records/second. Loss is 0.37783548. \n",
      "2021-03-09 14:31:54 INFO  DistriOptimizer$:427 - [Epoch 3 19712/20096][Iteration 468][Wall Clock 252.207613609s] Trained 128.0 records in 0.375785825 seconds. Throughput is 340.61954 records/second. Loss is 0.3657959. \n",
      "2021-03-09 14:31:54 INFO  DistriOptimizer$:427 - [Epoch 3 19840/20096][Iteration 469][Wall Clock 252.545651254s] Trained 128.0 records in 0.338037645 seconds. Throughput is 378.65607 records/second. Loss is 0.33585036. \n",
      "2021-03-09 14:31:55 INFO  DistriOptimizer$:427 - [Epoch 3 19968/20096][Iteration 470][Wall Clock 252.89515715s] Trained 128.0 records in 0.349505896 seconds. Throughput is 366.2313 records/second. Loss is 0.37148684. \n",
      "2021-03-09 14:31:55 INFO  DistriOptimizer$:427 - [Epoch 3 20096/20096][Iteration 471][Wall Clock 253.068954978s] Trained 128.0 records in 0.173797828 seconds. Throughput is 736.4879 records/second. Loss is 0.4367682. \n",
      "2021-03-09 14:31:55 INFO  DistriOptimizer$:472 - [Epoch 3 20096/20096][Iteration 471][Wall Clock 253.068954978s] Epoch finished. Wall clock time is 257250.507877 ms\n",
      "2021-03-09 14:31:55 INFO  DistriOptimizer$:111 - [Epoch 3 20096/20096][Iteration 471][Wall Clock 253.068954978s] Validate model...\n",
      "[Stage 1908:>                                                       (0 + 1) / 1]Warn: jep.JepException: <class 'StopIteration'>\n",
      "\tat jep.Jep.exec(Native Method)\n",
      "\tat jep.Jep.exec(Jep.java:478)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "2021-03-09 14:31:59 INFO  DistriOptimizer$:177 - [Epoch 3 20096/20096][Iteration 471][Wall Clock 253.068954978s] validate model throughput is 1192.237 records/second\n",
      "2021-03-09 14:31:59 INFO  DistriOptimizer$:180 - [Epoch 3 20096/20096][Iteration 471][Wall Clock 253.068954978s] Top1Accuracy is Accuracy(correct: 3721, count: 5000, accuracy: 0.7442)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<zoo.orca.learn.pytorch.estimator.PyTorchSparkEstimator at 0x7f6fd8b9c1d0>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "rmsprop = torch.optim.RMSprop(model2.parameters(), lr=0.001)\n",
    "est = Estimator.from_torch(model=model2, optimizer=rmsprop, loss=criterion, metrics=metrics)\n",
    "est.fit(data=train_loader, epochs=3, validation_data=val_loader, batch_size=batch_size, checkpoint_trigger=EveryEpoch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_orca_context()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tf2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5056d60bd69d51d1e2df40a6c6e7c71a949f2ed4ad3fa2ff8fce432a7c7c0fe5"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}